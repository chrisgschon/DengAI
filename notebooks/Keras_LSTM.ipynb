{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#untie local dependency\n",
    "import os\n",
    "cwd = os.getcwd().split('\\\\')\n",
    "local_repo_path = '\\\\'.join(cwd[:-1])\n",
    "raw_data_path = local_repo_path + r'\\data\\raw'\n",
    "processed_data_path = local_repo_path + '\\data\\processed'\n",
    "feature_path = local_repo_path + r'\\\\data\\\\features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature_fname = 'keras'\n",
    "sj_feature_train = pd.read_csv(feature_path + r'\\\\sj_train_' + output_feature_fname + '.csv', index_col=0)\n",
    "sj_feature_test = pd.read_csv(feature_path + r'\\\\sj_test_' + output_feature_fname + '.csv', index_col=0)\n",
    "iq_feature_train = pd.read_csv(feature_path + r'\\\\iq_train_' + output_feature_fname + '.csv', index_col=0)\n",
    "iq_feature_test = pd.read_csv(feature_path + r'\\\\iq_test_' + output_feature_fname + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.081814</td>\n",
       "      <td>-1.183554</td>\n",
       "      <td>-0.759571</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>-0.542448</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.559956</td>\n",
       "      <td>-0.583693</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.530953</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.053519</td>\n",
       "      <td>0.110260</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.510605</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.479789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4  total_cases\n",
       "0 -1.081814 -1.183554 -0.759571 -1.272727 -0.542448            4\n",
       "1 -0.559956 -0.583693 -0.214395 -0.272727 -0.541333            5\n",
       "2  0.006304 -0.005017 -0.214395  0.000000 -0.530953            4\n",
       "3 -0.061121 -0.053519  0.110260  0.227273 -0.510605            3\n",
       "4  0.144991  0.146063  0.741194  0.500000 -0.479789            6"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr_sj, X_val_sj  = sj_feature_train.drop('total_cases', axis = 1).iloc[:-val_len,:], sj_feature_train.drop('total_cases', axis = 1).iloc[-val_len:,:]\n",
    "\n",
    "Y_tr_sj, Y_val_sj = sj_feature_train['total_cases'].iloc[:-val_len], sj_feature_train['total_cases'].iloc[-val_len:]\n",
    "\n",
    "X_test_sj = sj_feature_test \n",
    "\n",
    "X_tr_iq, X_val_iq, = iq_feature_train.drop('total_cases', axis = 1).iloc[:-val_len,:], iq_feature_train.drop('total_cases', axis = 1).iloc[-val_len:,:]\n",
    "\n",
    "Y_tr_iq, Y_val_iq = iq_feature_train['total_cases'].iloc[:-val_len], iq_feature_train['total_cases'].iloc[-val_len:]\n",
    "\n",
    "X_test_iq = iq_feature_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_sj = sj_feature_train.drop('total_cases', axis = 1)\n",
    "Y_tr_sj = sj_feature_train['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.081814</td>\n",
       "      <td>-1.183554</td>\n",
       "      <td>-0.759571</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>-0.542448</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.559956</td>\n",
       "      <td>-0.583693</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.530953</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.053519</td>\n",
       "      <td>0.110260</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.510605</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.479789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4  total_cases\n",
       "0 -1.081814 -1.183554 -0.759571 -1.272727 -0.542448            4\n",
       "1 -0.559956 -0.583693 -0.214395 -0.272727 -0.541333            5\n",
       "2  0.006304 -0.005017 -0.214395  0.000000 -0.530953            4\n",
       "3 -0.061121 -0.053519  0.110260  0.227273 -0.510605            3\n",
       "4  0.144991  0.146063  0.741194  0.500000 -0.479789            6"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.350555</td>\n",
       "      <td>-0.359024</td>\n",
       "      <td>-0.294028</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.542448</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.399342</td>\n",
       "      <td>-0.410314</td>\n",
       "      <td>-0.490046</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.060573</td>\n",
       "      <td>-0.054077</td>\n",
       "      <td>0.306279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.530953</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.405372</td>\n",
       "      <td>-0.407526</td>\n",
       "      <td>0.361409</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-0.510605</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.268153</td>\n",
       "      <td>0.171516</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.479789</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4 city  year  weekofyear\n",
       "0 -0.350555 -0.359024 -0.294028 -0.500000 -0.542448   sj  2008          18\n",
       "1 -0.399342 -0.410314 -0.490046 -0.272727 -0.541333   sj  2008          19\n",
       "2 -0.060573 -0.054077  0.306279  0.000000 -0.530953   sj  2008          20\n",
       "3 -0.405372 -0.407526  0.361409  0.727273 -0.510605   sj  2008          21\n",
       "4 -0.266685 -0.268153  0.171516  0.227273 -0.479789   sj  2008          22"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var1(t-9)</th>\n",
       "      <th>var2(t-9)</th>\n",
       "      <th>var3(t-9)</th>\n",
       "      <th>var4(t-9)</th>\n",
       "      <th>var5(t-9)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.081814</td>\n",
       "      <td>-1.183554</td>\n",
       "      <td>-0.759571</td>\n",
       "      <td>-1.272727</td>\n",
       "      <td>-0.542448</td>\n",
       "      <td>-0.559956</td>\n",
       "      <td>-0.583693</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475538</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.477795</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-0.167904</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.231916</td>\n",
       "      <td>0.147014</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.077471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.559956</td>\n",
       "      <td>-0.583693</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>-0.541333</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.530953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.231916</td>\n",
       "      <td>0.147014</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.077471</td>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.346202</td>\n",
       "      <td>0.392037</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006304</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.214395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.530953</td>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.053519</td>\n",
       "      <td>0.110260</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.510605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347266</td>\n",
       "      <td>0.346202</td>\n",
       "      <td>0.392037</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.061121</td>\n",
       "      <td>-0.053519</td>\n",
       "      <td>0.110260</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.510605</td>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.479789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0.200139</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122671</td>\n",
       "      <td>0.292449</td>\n",
       "      <td>0.283206</td>\n",
       "      <td>0.441041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.479789</td>\n",
       "      <td>0.146087</td>\n",
       "      <td>0.157770</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.438229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292449</td>\n",
       "      <td>0.283206</td>\n",
       "      <td>0.441041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229068</td>\n",
       "      <td>0.428943</td>\n",
       "      <td>0.423693</td>\n",
       "      <td>0.422665</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.337125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  var1(t-9)  \\\n",
       "10   -1.081814   -1.183554   -0.759571   -1.272727   -0.542448  -0.559956   \n",
       "11   -0.559956   -0.583693   -0.214395   -0.272727   -0.541333   0.006304   \n",
       "12    0.006304   -0.005017   -0.214395    0.000000   -0.530953  -0.061121   \n",
       "13   -0.061121   -0.053519    0.110260    0.227273   -0.510605   0.144991   \n",
       "14    0.144991    0.146063    0.741194    0.500000   -0.479789   0.146087   \n",
       "\n",
       "    var2(t-9)  var3(t-9)  var4(t-9)  var5(t-9)    ...     var1(t-1)  \\\n",
       "10  -0.583693  -0.214395  -0.272727  -0.541333    ...      0.475538   \n",
       "11  -0.005017  -0.214395   0.000000  -0.530953    ...      0.225024   \n",
       "12  -0.053519   0.110260   0.227273  -0.510605    ...      0.347266   \n",
       "13   0.146063   0.741194   0.500000  -0.479789    ...      0.195423   \n",
       "14   0.157770   0.385911   0.500000  -0.438229    ...      0.292449   \n",
       "\n",
       "    var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)   var3(t)  \\\n",
       "10   0.469965   0.477795   0.727273  -0.167904  0.225024  0.231916  0.147014   \n",
       "11   0.231916   0.147014  -0.500000  -0.077471  0.347266  0.346202  0.392037   \n",
       "12   0.346202   0.392037   0.500000   0.019901  0.195423  0.200139  0.385911   \n",
       "13   0.200139   0.385911   0.000000   0.122671  0.292449  0.283206  0.441041   \n",
       "14   0.283206   0.441041   0.000000   0.229068  0.428943  0.423693  0.422665   \n",
       "\n",
       "     var4(t)   var5(t)  \n",
       "10 -0.500000 -0.077471  \n",
       "11  0.500000  0.019901  \n",
       "12  0.000000  0.122671  \n",
       "13  0.000000  0.229068  \n",
       "14  0.227273  0.337125  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_sj_wide = series_to_supervised(X_tr_sj, 10, 1)\n",
    "#Y_tr_sj = X_tr_sj['var6(t)']\n",
    "X_tr_sj_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_sj_wide.drop(['var1(t)', 'var2(t)', 'var3(t)', 'var4(t)', 'var5(t)'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#X_tr_sj = scaler.fit_transform(X_tr_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876, 1, 49) (876,) (50, 1, 49) (50,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = X_tr_sj_wide.values\n",
    "n_train = values.shape[0] - 50\n",
    "train = values[:n_train, :]\n",
    "test = values[n_train:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 876 samples, validate on 50 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.2184 - val_loss: 0.1281\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.1128 - val_loss: 0.0840\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0874 - val_loss: 0.0846\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0819 - val_loss: 0.0674\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0753 - val_loss: 0.0653\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0741 - val_loss: 0.0723\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0717 - val_loss: 0.0763\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0669 - val_loss: 0.0693\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0616 - val_loss: 0.0644\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0586 - val_loss: 0.0613\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0551 - val_loss: 0.0605\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0527 - val_loss: 0.0582\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0502 - val_loss: 0.0550\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0485 - val_loss: 0.0589\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0479 - val_loss: 0.0562\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0467 - val_loss: 0.0602\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0454 - val_loss: 0.0590\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0426 - val_loss: 0.0523\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0403 - val_loss: 0.0519\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0391 - val_loss: 0.0525\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0387 - val_loss: 0.0500\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0370 - val_loss: 0.0474\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0340 - val_loss: 0.0388\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0297 - val_loss: 0.0362\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0276 - val_loss: 0.0353\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0266 - val_loss: 0.0348\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0260 - val_loss: 0.0383\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0329\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0315\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0303 - val_loss: 0.0412\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0277 - val_loss: 0.0233\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0251 - val_loss: 0.0218\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0209 - val_loss: 0.0229\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0233 - val_loss: 0.0294\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0217 - val_loss: 0.0266\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0224 - val_loss: 0.0267\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0228 - val_loss: 0.0195\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0224 - val_loss: 0.0194\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0204 - val_loss: 0.0189\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0206 - val_loss: 0.0230\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0160 - val_loss: 0.0194\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0231\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0166 - val_loss: 0.0170\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0154 - val_loss: 0.0202\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0156 - val_loss: 0.0194\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0176 - val_loss: 0.0244\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b73ce3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1, 50)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sj = series_to_supervised(sj_feature_test.drop(['city','weekofyear', 'year'], axis = 1), 10, 1)\n",
    "X_test_sj.drop(['var1(t)', 'var2(t)', 'var3(t)', 'var4(t)', 'var5(t)'], axis = 1, inplace = True)\n",
    "X_test_sj = X_test_sj.values.reshape((X_test_sj.shape[0], 1, X_test_sj.shape[1]))\n",
    "X_test_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_3_input to have shape (1, 49) but got array with shape (1, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-5f43aa6db801>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_sj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                              'argument.')\n\u001b[0;32m   1146\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_3_input to have shape (1, 49) but got array with shape (1, 50)"
     ]
    }
   ],
   "source": [
    "model.predict(X_test_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
